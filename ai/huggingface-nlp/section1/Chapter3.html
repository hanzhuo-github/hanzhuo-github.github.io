<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.66" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/avatar.svg"><title>3. 微调预训练模型 | Hertz</title><meta name="description" content="记录日常工作学习生活的笔记">
    <link rel="preload" href="/assets/style-BJ1m9HFY.css" as="style"><link rel="stylesheet" href="/assets/style-BJ1m9HFY.css">
    <link rel="modulepreload" href="/assets/app-BhCVjEdW.js"><link rel="modulepreload" href="/assets/Chapter3.html-B302q7tl.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-1tPrXgE0.js">
    <link rel="prefetch" href="/assets/index.html-CNc4VlaD.js" as="script"><link rel="prefetch" href="/assets/access-model.html-BZRLm_zg.js" as="script"><link rel="prefetch" href="/assets/authentication.html-oYAQzqK3.js" as="script"><link rel="prefetch" href="/assets/index.html-BZEzUIzg.js" as="script"><link rel="prefetch" href="/assets/index.html-C6xHHOa0.js" as="script"><link rel="prefetch" href="/assets/index.html-3COa1mDk.js" as="script"><link rel="prefetch" href="/assets/deep-q-learning.html-BYaYQwMh.js" as="script"><link rel="prefetch" href="/assets/index.html-De3s3rVc.js" as="script"><link rel="prefetch" href="/assets/policy-gradient.html-BrAp0D3m.js" as="script"><link rel="prefetch" href="/assets/q-learning.html-BXz4GfjA.js" as="script"><link rel="prefetch" href="/assets/index.html-CuPZnc5f.js" as="script"><link rel="prefetch" href="/assets/index.html-ByYecHF_.js" as="script"><link rel="prefetch" href="/assets/introduction.html-DI--asXT.js" as="script"><link rel="prefetch" href="/assets/metrics.html-BKPjmszM.js" as="script"><link rel="prefetch" href="/assets/Chapter1.html-B2NBDM-O.js" as="script"><link rel="prefetch" href="/assets/Chapter2.html-CDornRy3.js" as="script"><link rel="prefetch" href="/assets/Chapter3.html-D5gGrmrl.js" as="script"><link rel="prefetch" href="/assets/index.html-C0zs2k9U.js" as="script"><link rel="prefetch" href="/assets/command.html-D5Ysh4DH.js" as="script"><link rel="prefetch" href="/assets/1-intro.html-BxzAADmy.js" as="script"><link rel="prefetch" href="/assets/10-hash-table.html-DK7rcZBX.js" as="script"><link rel="prefetch" href="/assets/11-binary-tree.html-BnYBNP7z.js" as="script"><link rel="prefetch" href="/assets/12-heap.html-DT5vKeoc.js" as="script"><link rel="prefetch" href="/assets/13-graph.html-BUdmB-V0.js" as="script"><link rel="prefetch" href="/assets/14-string-matching.html-EWELM04I.js" as="script"><link rel="prefetch" href="/assets/2-array.html-BEgK7plR.js" as="script"><link rel="prefetch" href="/assets/3-linked-list.html-BPdOV9gT.js" as="script"><link rel="prefetch" href="/assets/4-stack.html-kn3JmHuy.js" as="script"><link rel="prefetch" href="/assets/5-queue.html-DCtSqxSE.js" as="script"><link rel="prefetch" href="/assets/6-recursion.html-B0K4VRFn.js" as="script"><link rel="prefetch" href="/assets/7-sort.html-BiAoZJod.js" as="script"><link rel="prefetch" href="/assets/8-binary-search.html-C8yHF9M2.js" as="script"><link rel="prefetch" href="/assets/9-skip-list.html-HqMLgF00.js" as="script"><link rel="prefetch" href="/assets/factory.html-D_vmJQyH.js" as="script"><link rel="prefetch" href="/assets/index.html-D1Zz-vzO.js" as="script"><link rel="prefetch" href="/assets/interface.html-DLCMlVen.js" as="script"><link rel="prefetch" href="/assets/options.html-sucbnnZd.js" as="script"><link rel="prefetch" href="/assets/proxy.html-5WkSowEW.js" as="script"><link rel="prefetch" href="/assets/singleton.html-DdTe0dhR.js" as="script"><link rel="prefetch" href="/assets/strategy.html-CbGkxp4g.js" as="script"><link rel="prefetch" href="/assets/template.html-CsriG99z.js" as="script"><link rel="prefetch" href="/assets/index.html-qvCH2xn1.js" as="script"><link rel="prefetch" href="/assets/DOM.html-CuItKcV5.js" as="script"><link rel="prefetch" href="/assets/debounce-throttle.html-NphlZvc4.js" as="script"><link rel="prefetch" href="/assets/index.html-Hwvsumqd.js" as="script"><link rel="prefetch" href="/assets/script-defer_async.html-BPbzKuKl.js" as="script"><link rel="prefetch" href="/assets/1-module.html-BH7ily2j.js" as="script"><link rel="prefetch" href="/assets/2-ts.html-C2wbVjqw.js" as="script"><link rel="prefetch" href="/assets/3-commit-message.html-CcgNdVdR.js" as="script"><link rel="prefetch" href="/assets/4-git.html-BZ8Jebp3.js" as="script"><link rel="prefetch" href="/assets/index.html-BGGZI34t.js" as="script"><link rel="prefetch" href="/assets/closure.html-k-bqhqkD.js" as="script"><link rel="prefetch" href="/assets/currying.html-DqN4UBUT.js" as="script"><link rel="prefetch" href="/assets/index.html-CsSbrItM.js" as="script"><link rel="prefetch" href="/assets/js-string.html-DqfjxlLg.js" as="script"><link rel="prefetch" href="/assets/module.html-D9KvAzYB.js" as="script"><link rel="prefetch" href="/assets/prototype.html-DWvW3-G5.js" as="script"><link rel="prefetch" href="/assets/recurrent-request.html-Ce2PPW4C.js" as="script"><link rel="prefetch" href="/assets/this.html-DnUx_2QN.js" as="script"><link rel="prefetch" href="/assets/variable-type.html-BBAEP1u8.js" as="script"><link rel="prefetch" href="/assets/index.html-WmtWHYOS.js" as="script"><link rel="prefetch" href="/assets/intro.html-D3V4lP8B.js" as="script"><link rel="prefetch" href="/assets/lifecycle.html-CLBCRSkm.js" as="script"><link rel="prefetch" href="/assets/frame-design.html-Anymflre.js" as="script"><link rel="prefetch" href="/assets/index.html-C9OFN5Wg.js" as="script"><link rel="prefetch" href="/assets/reactive.html-C0DqYkTn.js" as="script"><link rel="prefetch" href="/assets/ref.html-BlROqhvn.js" as="script"><link rel="prefetch" href="/assets/render.html-DQXsMRhT.js" as="script"><link rel="prefetch" href="/assets/responsive-system.html-X-EVgQxp.js" as="script"><link rel="prefetch" href="/assets/index.html-BhKUEhBb.js" as="script"><link rel="prefetch" href="/assets/index.html-RQx-7sok.js" as="script"><link rel="prefetch" href="/assets/1-specification.html-WZopz7M0.js" as="script"><link rel="prefetch" href="/assets/2-basic.html-WoIgTWhs.js" as="script"><link rel="prefetch" href="/assets/index.html-DNSqazvT.js" as="script"><link rel="prefetch" href="/assets/1-memory.html-CKSB10LD.js" as="script"><link rel="prefetch" href="/assets/2-basic.html-BMN_vbqb.js" as="script"><link rel="prefetch" href="/assets/3-quick-start.html-Bv1rk-cX.js" as="script"><link rel="prefetch" href="/assets/index.html-Ba7eMiDA.js" as="script"><link rel="prefetch" href="/assets/Chapter1.html-4Bvl1F4L.js" as="script"><link rel="prefetch" href="/assets/Chapter2.html-DOsw3dpc.js" as="script"><link rel="prefetch" href="/assets/Chapter4.html-AKBklpfv.js" as="script"><link rel="prefetch" href="/assets/Chapter5.html-LDtMqwVI.js" as="script"><link rel="prefetch" href="/assets/Chapter6.html-Ctc_NS5M.js" as="script"><link rel="prefetch" href="/assets/Chapter1.html-BXDbtbVe.js" as="script"><link rel="prefetch" href="/assets/ArrayBuffer.html-r5dI3kkY.js" as="script"><link rel="prefetch" href="/assets/Blob.html-DiLBaCd5.js" as="script"><link rel="prefetch" href="/assets/Object.html-D6z3FCzx.js" as="script"><link rel="prefetch" href="/assets/Promise.html-C0HKfCHH.js" as="script"><link rel="prefetch" href="/assets/Symbol.html-5Wp6ttYW.js" as="script"><link rel="prefetch" href="/assets/bigint.html-DddZZSS-.js" as="script"><link rel="prefetch" href="/assets/generator.html-C9sB8PnF.js" as="script"><link rel="prefetch" href="/assets/iterables.html-xdgXETve.js" as="script"><link rel="prefetch" href="/assets/js-array.html-COykDHzA.js" as="script"><link rel="prefetch" href="/assets/modules.html-Dv4RaxPB.js" as="script"><link rel="prefetch" href="/assets/event-loop.html-XYv0_Juv.js" as="script"><link rel="prefetch" href="/assets/index.html-SKaszz5y.js" as="script"><link rel="prefetch" href="/assets/js-engine.html-B4DzGCpx.js" as="script"><link rel="prefetch" href="/assets/web-api.html-xKsReHGV.js" as="script"><link rel="prefetch" href="/assets/404.html-CLoq8jae.js" as="script"><link rel="prefetch" href="/assets/index.html-Bxt3V8zX.js" as="script"><link rel="prefetch" href="/assets/index.html-CL-f6XN4.js" as="script"><link rel="prefetch" href="/assets/index.html-BrANkhPp.js" as="script"><link rel="prefetch" href="/assets/index.html-BtKgzctD.js" as="script"><link rel="prefetch" href="/assets/index.html-bpcy0RaU.js" as="script"><link rel="prefetch" href="/assets/index.html-CoUhRa-l.js" as="script"><link rel="prefetch" href="/assets/index.html-CHXPxnkB.js" as="script"><link rel="prefetch" href="/assets/index.html-CGch6-qx.js" as="script"><link rel="prefetch" href="/assets/index.html-CPbG0zzI.js" as="script"><link rel="prefetch" href="/assets/index.html-CxiJPFRs.js" as="script"><link rel="prefetch" href="/assets/index.html-5Vzk0mYU.js" as="script"><link rel="prefetch" href="/assets/index.html-DEUeTtPj.js" as="script"><link rel="prefetch" href="/assets/index.html-DwwdJhbO.js" as="script"><link rel="prefetch" href="/assets/index.html-CVAmxNC1.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-Bp9IAFhl.js" as="script"><link rel="prefetch" href="/assets/giscus-C1S_t8z-.js" as="script"><link rel="prefetch" href="/assets/SearchResult-2FrQxiWg.js" as="script"><link rel="prefetch" href="/assets/Card-CPkZ_z6g.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-DTD3w-DM.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><!----><!----><span class="vp-site-name">Hertz</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><span class="font-icon icon fas fa-home" style=""></span><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="前端"><!--[--><span class="font-icon icon fas fa-laptop-code" style=""></span>前端<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/js/variable-type.html" aria-label="JavaScript"><!--[--><span class="font-icon icon iconfont icon-js" style=""></span><!--]-->JavaScript<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/browser/DOM.html" aria-label="浏览器"><!--[--><span class="font-icon icon iconfont icon-browser" style=""></span><!--]-->浏览器<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">框架</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/front-end/vue/frame-design.html" aria-label="Vue"><!--[--><span class="font-icon icon iconfont icon-vuejs" style=""></span><!--]-->Vue<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/front-end/react/intro.html" aria-label="React"><!--[--><span class="font-icon icon iconfont icon-react" style=""></span><!--]-->React<!----></a></li></ul></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/configuration//1-module.html" aria-label="工程化"><!--[--><span class="font-icon icon iconfont icon-project" style=""></span><!--]-->工程化<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/dev/" aria-label="开发相关"><!--[--><span class="font-icon icon fas fa-code" style=""></span><!--]-->开发相关<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="coding"><!--[--><span class="font-icon icon fas fa-keyboard" style=""></span>coding<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/data-structure/1-intro.html" aria-label="数据结构"><!--[--><span class="font-icon icon iconfont icon-ds" style=""></span><!--]-->数据结构<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/design-pattern/" aria-label="设计模式"><!--[--><span class="font-icon icon iconfont icon-dp" style=""></span><!--]-->设计模式<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/re/" aria-label="正则表达式"><!--[--><span class="font-icon icon iconfont icon-re" style=""></span><!--]-->正则表达式<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="其他"><!--[--><span class="font-icon icon fas fa-lemon" style=""></span>其他<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/ai/huggingface-nlp/" aria-label="huggingface"><!--[--><span class="font-icon icon iconfont icon-huggingface" style=""></span><!--]-->huggingface<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/hanzhuo-github/hanzhuo-github.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable active"><span class="font-icon icon iconfont icon-huggingface" style=""></span><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/ai/huggingface-nlp/" aria-label="Hugging Face NLP"><!---->Hugging Face NLP<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">👋	Hugging Face 初步</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter1.html" aria-label="1. Transformer Models"><!---->1. Transformer Models<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter2.html" aria-label="2. 使用 🤗 Transformers"><!---->2. 使用 🤗 Transformers<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/ai/huggingface-nlp/section1/Chapter3.html" aria-label="3. 微调预训练模型"><!---->3. 微调预训练模型<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter4.html" aria-label="4. 共享 Models 和 Tokenizers"><!---->4. 共享 Models 和 Tokenizers<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">👌 Hugging Face 深入</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">🤟 Hugging Face 高级</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon iconfont icon-rl" style=""></span><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/ai/deep-rl/" aria-label="Deep RL"><!---->Deep RL<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/" aria-label="Introduction"><!---->Introduction<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/q-learning.html" aria-label="Q-learning"><!---->Q-learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/deep-q-learning.html" aria-label="Deep Q-learning"><!---->Deep Q-learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/policy-gradient.html" aria-label="Policy Gradient with PyTorch"><!---->Policy Gradient with PyTorch<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><span class="font-icon icon iconfont icon-theory" style=""></span><span class="vp-sidebar-title">理论</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/theory/metrics.html" aria-label="机器学习的评价指标"><!---->机器学习的评价指标<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon iconfont icon-book" style=""></span><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/ai/statisticalLearning/" aria-label="ISL"><!---->ISL<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/statisticalLearning/" aria-label="链接"><!---->链接<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/statisticalLearning/introduction.html" aria-label="简介"><!---->简介<!----></a></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->3. 微调预训练模型</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Hertz</span></span><span property="author" content="Hertz"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2024年12月24日</span><meta property="datePublished" content="2024-12-24T06:48:31.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 13 分钟</span><meta property="timeRequired" content="PT13M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><div class="vp-toc-header">此页内容<!----><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-处理数据">1. 处理数据</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-从-hub-中加载数据集">1.1 从 Hub 中加载数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-数据集预处理">1.2 数据集预处理</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-3-动态填充-dynamic-padding">1.3 动态填充（Dynamic Padding）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-使用-trainer-api-进行微调">2. 使用 Trainer API 进行微调</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-训练-training">2.1 训练（Training）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-评估-evaluation">2.2 评估（Evaluation）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-使用-pytorch-训练">3. 使用 Pytorch 训练</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-准备">3.1 准备</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-training-loop">3.2 Training Loop</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-3-evaluation-loop">3.3 Evaluation Loop</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-4-使用-🤗-accelerate-进行加速">3.4 使用 🤗 Accelerate 进行加速</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#总结">总结</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><p>上一篇文章中介绍了如何使用 tokenizer 和预训练模型来进行推理。接下来我们将介绍如何在自己的数据集上进行微调（Fine-tuning）。在本篇文章中，你将了解到：</p><ul><li>如何从 Hub 中准备大型数据集</li><li>如何使用 high-level API 微调模型</li><li>如何使用自定义训练过程</li><li>如何利用 🤗 Accelerate 库在任何分布式设备上轻松运行自定义训练过程</li></ul><h2 id="_1-处理数据" tabindex="-1"><a class="header-anchor" href="#_1-处理数据"><span>1. 处理数据</span></a></h2><div class="hint-container note"><p class="hint-container-title">注</p><p>如果你不想了解这些细节，或者想先运行数据处理的整体代码，请直接从 <a href="#_2-%E4%BD%BF%E7%94%A8-trainer-api-%E6%88%96-keras-%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83">2</a> 开始阅读</p></div><p>Hub 中不仅有 models，还有很多 <a href="https://huggingface.co/datasets" target="_blank" rel="noopener noreferrer">datasets</a>.</p><p>我们将使用 <a href="https://aclanthology.org/I05-5002.pdf" target="_blank" rel="noopener noreferrer">MRPC（Microsoft Research Paraphrase Corpus）数据集</a>，它是 <a href="https://gluebenchmark.com/" target="_blank" rel="noopener noreferrer">GLUE benchmark</a> 的十个数据集之一，该 benchmark 用来衡量 ML 模型在 10 个不同文本分类任务中的性能。MRPC 数据集有 5801 个句子对，每个句子对有一个标签来指明两个句子是否同义。</p><h3 id="_1-1-从-hub-中加载数据集" tabindex="-1"><a class="header-anchor" href="#_1-1-从-hub-中加载数据集"><span>1.1 从 Hub 中加载数据集</span></a></h3><p>🤗 Datasets 库提供了简单易用的命令来下载并缓存 Hub 中的数据集</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</span>
<span class="line"></span>
<span class="line">raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">raw_datasets</span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">DatasetDict<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">    train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">3668</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line">    validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">408</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line">    test<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">1725</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>我们得到了一个 <code>DatasetDict</code> 对象，它有 training set, validation set, 和 test set。每一个集合中包含这样几列：sentence1、sentence2、label、idx，以及行数（即数据数量）。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>缓存路径为 <code>~/.cache/huggingface/datasets</code> 你可以通过设置 <code>HF_HOME</code> 环境变量来自定义缓存路径。</p></div><p>你可以先看看数据：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">raw_train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span></span>
<span class="line">raw_train_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#39;</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#39;</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;label&#39;</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div><p>可以通过查看 raw_train_dataset 的 <code>features</code> 来查看 label 的含义。0 是 not_equivalent，1 是 equivalent。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">raw_train_dataset<span class="token punctuation">.</span>features</span>
<span class="line"></span></code></pre></div><div class="language-text" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">{&#39;sentence1&#39;: Value(dtype=&#39;string&#39;, id=None),</span>
<span class="line"> &#39;sentence2&#39;: Value(dtype=&#39;string&#39;, id=None),</span>
<span class="line"> &#39;label&#39;: ClassLabel(names=[&#39;not_equivalent&#39;, &#39;equivalent&#39;], id=None),</span>
<span class="line"> &#39;idx&#39;: Value(dtype=&#39;int32&#39;, id=None)}</span>
<span class="line"></span></code></pre></div><h3 id="_1-2-数据集预处理" tabindex="-1"><a class="header-anchor" href="#_1-2-数据集预处理"><span>1.2 数据集预处理</span></a></h3><p>我们需要将文本转化成数字表示，这样模型才能进行处理。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</span>
<span class="line"></span>
<span class="line">checkpoint <span class="token operator">=</span> <span class="token string">&quot;bert-base-uncased&quot;</span></span>
<span class="line">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span></span>
<span class="line">tokenized_sentences_1 <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">tokenized_sentences_2 <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面的代码确实将文本转化成了数字表示，但是我们需要传入句子对</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">&quot;This is the first sentence.&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;This is the second one.&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2003</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">2034</span><span class="token punctuation">,</span> <span class="token number">6251</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2003</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">2117</span><span class="token punctuation">,</span> <span class="token number">2028</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> </span>
<span class="line">  <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> </span>
<span class="line">  <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token string">&#39;[CLS]&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;this&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;is&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;the&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;[SEP]&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;this&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;is&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;the&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;second&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;one&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;[SEP]&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre></div><p>我们在上一篇文章中介绍了 input_ids 和 attention_mask，没有介绍 token_type_ids。在这个例子中，token_type_ids 表示输入的哪部分是第一个句子，哪一个是第二个句子。</p><p>我们可以看到模型需要的输入形式是 [CLS] sentence1 [SEP] sentence2 [SEP]（使用不同的 checkpoints 时该结构会不一样），所以 token_type_ids（使用其他的 checkpoints 时，可能不会有 token_type_ids） 的值是</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">[</span><span class="token string">&#39;[CLS]&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;this&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;is&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;the&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;[SEP]&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;this&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;is&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;the&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;second&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;one&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;.&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;[SEP]&#39;</span><span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">[</span>      <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">0</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>       <span class="token number">0</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">,</span>   <span class="token number">0</span><span class="token punctuation">,</span>       <span class="token number">0</span><span class="token punctuation">,</span>      <span class="token number">1</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">,</span>        <span class="token number">1</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">,</span>   <span class="token number">1</span><span class="token punctuation">,</span>       <span class="token number">1</span><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre></div><p>我们可以为 tokenizer 提供句子对列表</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tokenized_dataset <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span></span>
<span class="line">    raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></span>
<span class="line">    truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这是有用的，但是也有一些不足。tokenization 过程中需要在 RAM 中保存整个数据集，如果你的 RAM 空间不足将会有问题。</p><p>我们使用 <code>Dataset.map()</code> 方法来构建数据集，它不会将整个 dataset 都加载到内存中，且结果会被缓存，下次执行时不需要重复计算。首先创建函数对输入进行 tokenization：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">tokenized_function</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> example<span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>我们将 padding 参数去掉了，因为将所有的数据 padding 到最大长度效率不高，更好的做法是当我们构建一个 batch 时 pad 该 batch 中的数据，这样我们只需要将长度填充为该 batch 中的最大长度。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 设置 batched 为 True，使得同时对数据集中的多个元素同时做处理，加速了预处理</span></span>
<span class="line">tokenized_datasets <span class="token operator">=</span> raw_datasets<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenized_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">tokenized_datasets</span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">DatasetDict<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">    train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">3668</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line">    validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">408</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line">    test<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">        features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&#39;sentence1&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;sentence2&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;label&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;idx&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        num_rows<span class="token punctuation">:</span> <span class="token number">1725</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>🤗 Datasets 库用 map() 函数的处理方式是想数据集中添加新的字段，新的字段即预处理函数返回的字典中的每个键。</p><p>可以通过传递 <code>num_proc</code> 参数给 map() 以启动多进程。🤗 Tokenizers 库已经使用了多线程，于是这里我们没有启用多进程。</p><p>最后一项任务就是在每个 batch 进行 padding，即 dynamic padding.</p><h3 id="_1-3-动态填充-dynamic-padding" tabindex="-1"><a class="header-anchor" href="#_1-3-动态填充-dynamic-padding"><span>1.3 动态填充（Dynamic Padding）</span></a></h3><p>在批处理中这将数据整理到一个 batch 的函数称为 collate function. 它是构建 DataLoader 时的一个参数，默认是一个函数，它把你的数据集转化为 Pytorch tensors，并将它们拼接起来。</p><p>🤗 Transformers 库通过 <code>DataCollatorWithPadding</code> 提供了 collate function。它接收一个 tokenizer (以获取 padding token、确定是在输入的左侧还是右侧进行 padding)。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorWithPadding</span>
<span class="line"></span>
<span class="line">data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><details class="hint-container details"><summary>我们可以验证一下 data_collator 是否能在 batch 上进行正确的 padding</summary><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">samples <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span></span>
<span class="line">samples <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> samples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">&quot;idx&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> samples<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">]</span></span>
<span class="line"><span class="token comment"># [50, 59, 47, 67, 59, 50, 62, 32]</span></span>
<span class="line"></span></code></pre></div><p>我们取了 train set 中前 8 个作为一个 batch，去掉了 idx、sentence1、sentence2 字段。</p><p>input_ids 的最大长度为 67，则这个 batch 经过 padding 之后将会被填充到 67</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">batch <span class="token operator">=</span> data_collator<span class="token punctuation">(</span>samples<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>shape <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;labels&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div></details><p>现在，我们已经将原数数据转化成模型可处理的 batches，下面我们要进行微调了。</p><h2 id="_2-使用-trainer-api-进行微调" tabindex="-1"><a class="header-anchor" href="#_2-使用-trainer-api-进行微调"><span>2. 使用 Trainer API 进行微调</span></a></h2><p>🤗 Transformers 提供了 <code>Trainer</code> 类来微调各种预训练模型。最难的步骤大概是为 <code>Trainer.train()</code> 配置运行环境。</p><p>我们快速回顾一下上一部分的预处理：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</span>
<span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> DataCollatorWithPadding</span>
<span class="line"></span>
<span class="line">raw_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">checkpoint <span class="token operator">=</span> <span class="token string">&quot;bert-base-uncased&quot;</span></span>
<span class="line">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> example<span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">tokenized_datasets <span class="token operator">=</span> raw_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-1-训练-training" tabindex="-1"><a class="header-anchor" href="#_2-1-训练-training"><span>2.1 训练（Training）</span></a></h3><p>第一步，在我们定义 <code>Trainer</code> 之前我们要先定义 <code>TrainingArguments</code> 类，它包含 <code>Trainer</code> 训练和评估时所用的全部超参。必须提供的唯一参数是训练模型的存储路径，也是 checkpoints 的路径。其余的参数都可以设置为默认值，对于基础的微调来说表现得也很不错。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments</span>
<span class="line"></span>
<span class="line">training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span><span class="token string">&quot;test-trainer&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><div class="hint-container tip"><p class="hint-container-title">提示</p><p>如果你想在训练过程中自动上传你的模型到 Hub 上，可以在 TrainingArguments 中传递 push_to_hub=True。我们将在 <a class="route-link" href="/ai/huggingface-nlp/section1/Chapter4.html">Chapter 4</a> 中详细介绍。</p><details class="hint-container details"><summary>🤗 官方示例 accelerate 版本错误解决方案</summary><p>在 CoLab 上运行 🤗 官方示例时，如果遇到下面的错误，</p><div class="language-text" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">ImportError: Using the `Trainer` with `PyTorch` requires `accelerate&gt;=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`</span>
<span class="line"></span></code></pre></div><p>可以尝试下面方法，首先更新 accelerate 和 transformers</p><div class="language-text" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">!pip install -U accelerate</span>
<span class="line">!pip install -U transformers</span>
<span class="line"></span></code></pre></div><p>然后 Restart runtime</p></details></div><p>第二步，定义模型。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification</span>
<span class="line"></span>
<span class="line">model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>在实例化 model 时你会看到 warning，这是因为 BERT 没有对句子对进行过预训练，于是预训练模型的 head 被替换成了做 sequence classification 的 head。</p><p>现在我们可以定义 <code>Trainer</code> 了，将我们之前构造的对象（model, training_args, training &amp; validation datasets, data_collator 以及 tokenizer）作为参数传递。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer</span>
<span class="line"></span>
<span class="line">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span></span>
<span class="line">    model<span class="token punctuation">,</span></span>
<span class="line">    training_args<span class="token punctuation">,</span></span>
<span class="line">    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span></span>
<span class="line">    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">注意</p><p>当在 Trainer 中传递 tokenizer 时，Trainer 使用的默认 data_collator 和我们之前使用 DataCollatorWithPadding 定义的是一样的。所以我们可以不传递 data_collator。</p></div><p>调用 Trainer 的 <code>train()</code> 方法，我们就可以在自己的数据集上微调模型了。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>运行上面代码后，我们将开始微调，每 500 steps 会输出一次 training loss。但是它不会告诉你这个模型表现得怎么样，因为：</p><ul><li>我们没有配置 Trainer 让它在训练时进行评估。想要进行评估可以设置 <code>evaluation_strategy</code> 为 “steps”（每eval_steps 进行评估） 或 “epoch”（在每个 epoch 之后进行评估）。</li><li>我们没有为 Trainer 提供评估的方法。我们可以传递通过 <code>compute_metrics()</code> 函数提供计算模型性能的方法。没有提供该方法的话，评估时会直接输出 loss，并不直观。</li></ul><h3 id="_2-2-评估-evaluation" tabindex="-1"><a class="header-anchor" href="#_2-2-评估-evaluation"><span>2.2 评估（Evaluation）</span></a></h3><p>我们来看一下如何构建 <code>compute_metrics()</code> 函数并在训练时使用它。</p><p>可以使用 <code>Trainer.predict()</code> 方法进行预测。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">predictions <span class="token operator">=</span> trainer<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>predictions<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> predictions<span class="token punctuation">.</span>label_ids<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># (408, 2) (408,)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token comment"># predictions.predictions 的输出是 logits，为了获得预测结果，可以将 logits 的最大值的取出</span></span>
<span class="line">preds <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>predictions<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>Trainer.predict()</code> 的输出是一个命名元祖，有三个字段：predictions, label_ids, 和 metrics。metrics 字段包含 loss、时间 metrics（预测用了多长时间，总计时长、平均时长）。如果我们自定义了 compute_metrics() 函数并传递给了 Trainer，那么该字段还会包括 compute_metrics() 函数返回的 metrics。</p><p>构建 compute_metrics() 需要用到 <a href="https://github.com/huggingface/evaluate/" target="_blank" rel="noopener noreferrer">🤗 Evaluate 库</a>。我们可以使用 <code>evaluate.load()</code> 函数加载与 MRPC 数据集有关的 metrics，它返回的对象有 <code>compute()</code> 方法，可以用来进行 metric calculation。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> evaluate</span>
<span class="line"></span>
<span class="line">metric <span class="token operator">=</span> evaluate<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>preds<span class="token punctuation">,</span> references<span class="token operator">=</span>predictions<span class="token punctuation">.</span>label_ids<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;accuracy&#39;</span><span class="token punctuation">:</span> <span class="token number">0.8578431372549019</span><span class="token punctuation">,</span> <span class="token string">&#39;f1&#39;</span><span class="token punctuation">:</span> <span class="token number">0.8996539792387542</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div><p>我们最终得到了 accuracy 和 f1。这是用来衡量 MRPC 的 metrics。</p><p>现在我们可以定义 <code>compute_metrics()</code> 函数了：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>eval_preds<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    metric <span class="token operator">=</span> evaluate<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">    logits<span class="token punctuation">,</span> labels <span class="token operator">=</span> eval_preds</span>
<span class="line">    predictions <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>labels<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>如果想要在每个 epoch 之后输出这些 metrics，我们可以在 Trainer 中传递 <code>compute_metrics()</code> 函数</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span><span class="token string">&quot;test-trainer&quot;</span><span class="token punctuation">,</span> evaluation_strategy<span class="token operator">=</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">)</span></span>
<span class="line">model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span></span>
<span class="line">    model<span class="token punctuation">,</span></span>
<span class="line">    training_args<span class="token punctuation">,</span></span>
<span class="line">    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span></span>
<span class="line">    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span></span>
<span class="line">    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这次我们再执行 <code>trainer.train()</code> 时就会在每个 epoch 结束时输出 validation loss 和 metrics。</p><p><code>Trainer</code> 在多 GPU 和多 TPU 上开箱即用，且提供了很多配置项，比如通过配置 <code>fp16=True</code> 来启动 mixed-precision 训练。我们会在第 10 章介绍这些配置项。</p><h2 id="_3-使用-pytorch-训练" tabindex="-1"><a class="header-anchor" href="#_3-使用-pytorch-训练"><span>3. 使用 Pytorch 训练</span></a></h2><p>在 2 中我们介绍了如何使用 <code>Trainer</code> 类进行微调。现在我们不使用 <code>Trainer</code> 来达到同样的目的。</p><p>数据预处理的方式和之前介绍的一样，我们假定你已经完成了这步。</p><details class="hint-container details"><summary>数据预处理</summary><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</span>
<span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> DataCollatorWithPadding</span>
<span class="line"></span>
<span class="line">raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">checkpoint <span class="token operator">=</span> <span class="token string">&quot;bert-base-uncased&quot;</span></span>
<span class="line">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> example<span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line">tokenized_datasets <span class="token operator">=</span> raw_datasets<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="_3-1-准备" tabindex="-1"><a class="header-anchor" href="#_3-1-准备"><span>3.1 准备</span></a></h3><p>之前我们直接将 tokenized_datasets 传给 <code>Trainer</code> 让它自己处理，现在我们需要手动处理：</p><ul><li>tokenized_datasets 中的 sentence1, sentence2, idx 不是 model 需要的输入，需要删掉</li><li>将列 label 改为 labels</li><li>将 dataset 的格式设为 Pytorch tensor</li></ul><p>对应的代码：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>remove_columns<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;idx&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>rename_column<span class="token punctuation">(</span><span class="token string">&quot;label&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;labels&quot;</span><span class="token punctuation">)</span></span>
<span class="line">tokenized_datasets<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">&quot;torch&quot;</span><span class="token punctuation">)</span></span>
<span class="line">tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names</span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">[</span><span class="token string">&#39;labels&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre></div><p>接下来在定义 training loop 之前，还要先定义几个对象：</p><h4 id="_3-1-1-数据加载器-dataloader-用于迭代批次" tabindex="-1"><a class="header-anchor" href="#_3-1-1-数据加载器-dataloader-用于迭代批次"><span>3.1.1 数据加载器（dataloader）：用于迭代批次</span></a></h4><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</span>
<span class="line"></span>
<span class="line">train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span></span>
<span class="line">    tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>data_collator</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line">eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span></span>
<span class="line">    tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>data_collator</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>快速检验下是否有错</summary><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">break</span></span>
<span class="line"><span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>shape <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;labels&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;input_ids&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;token_type_ids&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token string">&#39;attention_mask&#39;</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div></details><p>至此，数据预处理完成了。</p><h4 id="_3-1-2-model" tabindex="-1"><a class="header-anchor" href="#_3-1-2-model"><span>3.1.2 model</span></a></h4><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification</span>
<span class="line"></span>
<span class="line">model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><details class="hint-container details"><summary>快速检验下是否有错</summary><p>我们将上面检验 dataloader 是否出错时使用的 batch 传递给 model</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>loss<span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tensor<span class="token punctuation">(</span><span class="token number">0.6617</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NllLossBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div></details><h4 id="_3-1-3-优化器-optimizer" tabindex="-1"><a class="header-anchor" href="#_3-1-3-优化器-optimizer"><span>3.1.3 优化器（optimizer）</span></a></h4><p>我们使用 <code>Trainer</code> 的默认 optimizer：<a href="https://arxiv.org/abs/1711.05101" target="_blank" rel="noopener noreferrer"><code>AdamW</code></a>，它和 <code>Adam</code> 类似，主要差异在于他们的权重衰减正则化（weight decay regularization）不同。</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW</span>
<span class="line"></span>
<span class="line">optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">5e-5</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><h4 id="_3-1-4-学习率调度器-learning-rate-scheduler" tabindex="-1"><a class="header-anchor" href="#_3-1-4-学习率调度器-learning-rate-scheduler"><span>3.1.4 学习率调度器（learning rate scheduler）</span></a></h4><p>默认的 learning rate scheduler 实现的是简单的从 5e-5 到 0 的线性衰减。为了定义学习率调度器，我们需要知道要进行多少 training steps，即 epoch 乘 training batches（training dataloader 的长度）。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> get_scheduler</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Trainer 默认训练 3 轮</span></span>
<span class="line">num_epochs <span class="token operator">=</span> <span class="token number">3</span></span>
<span class="line">num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span></span>
<span class="line">lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&quot;linear&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">    num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">    num_training_steps<span class="token operator">=</span>num_training_steps<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span>    <span class="token comment"># 1377</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-2-training-loop" tabindex="-1"><a class="header-anchor" href="#_3-2-training-loop"><span>3.2 Training Loop</span></a></h3><p>我们可以设置 device 为 gpu 以让 model在 GPU 上运行：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span></span>
<span class="line">model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><p>现在可以开始训练啦！为了让我们知道训练的进度，可以使用进度条（<code>tqdm</code> 库）。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm</span>
<span class="line"></span>
<span class="line">progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>number_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span></span>
<span class="line">        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span></span>
<span class="line">        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss</span>
<span class="line">        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下面我们添加一些输出，以在训练过程中查看训练效果</p><h3 id="_3-3-evaluation-loop" tabindex="-1"><a class="header-anchor" href="#_3-3-evaluation-loop"><span>3.3 Evaluation Loop</span></a></h3><p>我们仍然使用 🤗 Evaluate 库提供的 metric。之前我们用过 metric.compute() 方法了。在 prediction loop 中使用 add_batch() ，metrics 会跟着 batches 累积，当我们将全部 batch 的结果累积后就可以使用 metric.compute() 得到最后的结果。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> evaluate</span>
<span class="line"></span>
<span class="line">metric <span class="token operator">=</span> evaluate<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span></span>
<span class="line">model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> batch <span class="token keyword">in</span> eval_dataloader<span class="token punctuation">:</span></span>
<span class="line">    batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span></span>
<span class="line">    </span>
<span class="line">    logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits</span>
<span class="line">    predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    metric<span class="token punctuation">.</span>add_batch<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">&quot;labels&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;accuracy&#39;</span><span class="token punctuation">:</span> <span class="token number">0.8431372549019608</span><span class="token punctuation">,</span> <span class="token string">&#39;f1&#39;</span><span class="token punctuation">:</span> <span class="token number">0.8907849829351535</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre></div><h3 id="_3-4-使用-🤗-accelerate-进行加速" tabindex="-1"><a class="header-anchor" href="#_3-4-使用-🤗-accelerate-进行加速"><span>3.4 使用 🤗 Accelerate 进行加速</span></a></h3><p>使用 🤗 Accelerate 我们可以在多个 GPU 或 TPU 上进行分布式训练。</p><p>我们在之前的代码上进行简单修改即可完成：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line highlighted"><span class="token operator">+</span> <span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator</span>
<span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> get_scheduler</span>
<span class="line"></span>
<span class="line highlighted"><span class="token operator">+</span> accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e-5</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line highlighted"><span class="token operator">-</span> device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span></span>
<span class="line highlighted"><span class="token operator">-</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line highlighted"><span class="token operator">+</span> train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span></span>
<span class="line highlighted"><span class="token operator">+</span>     train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer</span>
<span class="line highlighted"><span class="token operator">+</span> <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">num_epochs <span class="token operator">=</span> <span class="token number">3</span></span>
<span class="line">num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span></span>
<span class="line">lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&quot;linear&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">    num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">    num_training_steps<span class="token operator">=</span>num_training_steps<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span></span>
<span class="line highlighted"><span class="token operator">-</span>       batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span></span>
<span class="line">        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss</span>
<span class="line highlighted"><span class="token operator">-</span>       loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line highlighted"><span class="token operator">+</span>       accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line"></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>🤗 Accelerate 会帮你处理设备的问题，所以你可以删除 device 那段代码（你也可以使用 <code>accelerator.device</code> 来代替 <code>device</code>）。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>为了充分利用集群 TPU 的加速，建议把所有的数据填充到固定的长度（配置 tokenizer 的 <code>padding=&quot;max_length&quot;</code>）。</p></div><details class="hint-container details"><summary>如果你要复制粘贴分布式训练的代码，请看这里</summary><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator</span>
<span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> get_scheduler</span>
<span class="line"></span>
<span class="line">accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e-5</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">train_dl<span class="token punctuation">,</span> eval_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span></span>
<span class="line">    train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">num_epochs <span class="token operator">=</span> <span class="token number">3</span></span>
<span class="line">num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dl<span class="token punctuation">)</span></span>
<span class="line">lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&quot;linear&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">    num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span></span>
<span class="line">    num_training_steps<span class="token operator">=</span>num_training_steps<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span></span>
<span class="line">        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss</span>
<span class="line">        accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><p>将代码存到 train.py 中，该脚本可以在任何分布式设备上运行。</p><div class="language-bash" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">accelerate config</span>
<span class="line"></span></code></pre></div><p>回答弹出的问题，然后它会将你的答案写入配置文件中。然后你可以使用下面的命令使用该配置文件启动分布式训练。</p><div class="language-bash" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">accelerate launch train.py</span>
<span class="line"></span></code></pre></div><p>如果你想在 Notebook 中尝试，你把代码贴到函数下面（比如 <code>training_function()</code> ），然后在 cell 中执行：</p><div class="language-python" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> accelerate <span class="token keyword">import</span> notebook_launcher</span>
<span class="line"></span>
<span class="line">notebook_launcher<span class="token punctuation">(</span>training_function<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre></div><div class="hint-container info"><p class="hint-container-title">更多示例</p><p>你可以在 <a href="https://github.com/huggingface/accelerate/tree/main/examples" target="_blank" rel="noopener noreferrer">🤗 Accelerate repo</a> 中查看更多示例。</p></div><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>在前两章中你了解了 model 和 tokenizer，现在你学会了如何微调。回顾本章：</p><ul><li>在 Hub 中查看并下载 datasets</li><li>学会了如何加载、预处理数据集，包括动态填充和 collator</li><li>实现微调以及评估</li><li>较底层实现 training loop</li><li>使用 🤗 Accelerate 以在 GPU 集群或 TPU 集群上进行训练</li></ul></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/hanzhuo-github/hanzhuo-github.github.io/edit/main/src/ai/huggingface-nlp/section1/Chapter3.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><span class="vp-meta-info" data-allow-mismatch="text">2024/12/24 06:48:31</span></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: hanzhuosoul@gmail.com">Hertz</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/ai/huggingface-nlp/section1/Chapter2.html" aria-label="2. 使用 🤗 Transformers"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->2. 使用 🤗 Transformers</div></a><a class="route-link auto-link next" href="/ai/huggingface-nlp/section1/Chapter4.html" aria-label="4. 共享 Models 和 Tokenizers"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">4. 共享 Models 和 Tokenizers<!----></div></a></nav><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div class="loading-icon-wrapper" style="display:flex;align-items:center;justify-content:center;height:96px"><svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" preserveAspectRatio="xMidYMid" viewBox="25 25 50 50"><animateTransform attributeName="transform" type="rotate" dur="2s" keyTimes="0;1" repeatCount="indefinite" values="0;360"></animateTransform><circle cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round"><animate attributeName="stroke-dasharray" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="1,200;90,200;1,200"></animate><animate attributeName="stroke-dashoffset" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="0;-35px;-125px"></animate></circle></svg></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2024 Hertz </div></footer></div><!--]--><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BhCVjEdW.js" defer></script>
  </body>
</html>

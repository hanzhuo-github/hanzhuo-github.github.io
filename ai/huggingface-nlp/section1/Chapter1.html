<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.66" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/avatar.svg"><title>1. Transformer Models | Hertz</title><meta name="description" content="记录日常工作学习生活的笔记">
    <link rel="preload" href="/assets/style-BJ1m9HFY.css" as="style"><link rel="stylesheet" href="/assets/style-BJ1m9HFY.css">
    <link rel="modulepreload" href="/assets/app-BhCVjEdW.js"><link rel="modulepreload" href="/assets/Chapter1.html-4Bvl1F4L.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-1tPrXgE0.js">
    <link rel="prefetch" href="/assets/index.html-CNc4VlaD.js" as="script"><link rel="prefetch" href="/assets/access-model.html-BZRLm_zg.js" as="script"><link rel="prefetch" href="/assets/authentication.html-oYAQzqK3.js" as="script"><link rel="prefetch" href="/assets/index.html-BZEzUIzg.js" as="script"><link rel="prefetch" href="/assets/index.html-C6xHHOa0.js" as="script"><link rel="prefetch" href="/assets/index.html-3COa1mDk.js" as="script"><link rel="prefetch" href="/assets/deep-q-learning.html-BYaYQwMh.js" as="script"><link rel="prefetch" href="/assets/index.html-De3s3rVc.js" as="script"><link rel="prefetch" href="/assets/policy-gradient.html-BrAp0D3m.js" as="script"><link rel="prefetch" href="/assets/q-learning.html-BXz4GfjA.js" as="script"><link rel="prefetch" href="/assets/index.html-CuPZnc5f.js" as="script"><link rel="prefetch" href="/assets/index.html-ByYecHF_.js" as="script"><link rel="prefetch" href="/assets/introduction.html-DI--asXT.js" as="script"><link rel="prefetch" href="/assets/metrics.html-BKPjmszM.js" as="script"><link rel="prefetch" href="/assets/Chapter1.html-B2NBDM-O.js" as="script"><link rel="prefetch" href="/assets/Chapter2.html-CDornRy3.js" as="script"><link rel="prefetch" href="/assets/Chapter3.html-D5gGrmrl.js" as="script"><link rel="prefetch" href="/assets/index.html-C0zs2k9U.js" as="script"><link rel="prefetch" href="/assets/command.html-D5Ysh4DH.js" as="script"><link rel="prefetch" href="/assets/1-intro.html-BxzAADmy.js" as="script"><link rel="prefetch" href="/assets/10-hash-table.html-DK7rcZBX.js" as="script"><link rel="prefetch" href="/assets/11-binary-tree.html-BnYBNP7z.js" as="script"><link rel="prefetch" href="/assets/12-heap.html-DT5vKeoc.js" as="script"><link rel="prefetch" href="/assets/13-graph.html-BUdmB-V0.js" as="script"><link rel="prefetch" href="/assets/14-string-matching.html-EWELM04I.js" as="script"><link rel="prefetch" href="/assets/2-array.html-BEgK7plR.js" as="script"><link rel="prefetch" href="/assets/3-linked-list.html-BPdOV9gT.js" as="script"><link rel="prefetch" href="/assets/4-stack.html-kn3JmHuy.js" as="script"><link rel="prefetch" href="/assets/5-queue.html-DCtSqxSE.js" as="script"><link rel="prefetch" href="/assets/6-recursion.html-B0K4VRFn.js" as="script"><link rel="prefetch" href="/assets/7-sort.html-BiAoZJod.js" as="script"><link rel="prefetch" href="/assets/8-binary-search.html-C8yHF9M2.js" as="script"><link rel="prefetch" href="/assets/9-skip-list.html-HqMLgF00.js" as="script"><link rel="prefetch" href="/assets/factory.html-D_vmJQyH.js" as="script"><link rel="prefetch" href="/assets/index.html-D1Zz-vzO.js" as="script"><link rel="prefetch" href="/assets/interface.html-DLCMlVen.js" as="script"><link rel="prefetch" href="/assets/options.html-sucbnnZd.js" as="script"><link rel="prefetch" href="/assets/proxy.html-5WkSowEW.js" as="script"><link rel="prefetch" href="/assets/singleton.html-DdTe0dhR.js" as="script"><link rel="prefetch" href="/assets/strategy.html-CbGkxp4g.js" as="script"><link rel="prefetch" href="/assets/template.html-CsriG99z.js" as="script"><link rel="prefetch" href="/assets/index.html-qvCH2xn1.js" as="script"><link rel="prefetch" href="/assets/DOM.html-CuItKcV5.js" as="script"><link rel="prefetch" href="/assets/debounce-throttle.html-NphlZvc4.js" as="script"><link rel="prefetch" href="/assets/index.html-Hwvsumqd.js" as="script"><link rel="prefetch" href="/assets/script-defer_async.html-BPbzKuKl.js" as="script"><link rel="prefetch" href="/assets/1-module.html-BH7ily2j.js" as="script"><link rel="prefetch" href="/assets/2-ts.html-C2wbVjqw.js" as="script"><link rel="prefetch" href="/assets/3-commit-message.html-CcgNdVdR.js" as="script"><link rel="prefetch" href="/assets/4-git.html-BZ8Jebp3.js" as="script"><link rel="prefetch" href="/assets/index.html-BGGZI34t.js" as="script"><link rel="prefetch" href="/assets/closure.html-k-bqhqkD.js" as="script"><link rel="prefetch" href="/assets/currying.html-DqN4UBUT.js" as="script"><link rel="prefetch" href="/assets/index.html-CsSbrItM.js" as="script"><link rel="prefetch" href="/assets/js-string.html-DqfjxlLg.js" as="script"><link rel="prefetch" href="/assets/module.html-D9KvAzYB.js" as="script"><link rel="prefetch" href="/assets/prototype.html-DWvW3-G5.js" as="script"><link rel="prefetch" href="/assets/recurrent-request.html-Ce2PPW4C.js" as="script"><link rel="prefetch" href="/assets/this.html-DnUx_2QN.js" as="script"><link rel="prefetch" href="/assets/variable-type.html-BBAEP1u8.js" as="script"><link rel="prefetch" href="/assets/index.html-WmtWHYOS.js" as="script"><link rel="prefetch" href="/assets/intro.html-D3V4lP8B.js" as="script"><link rel="prefetch" href="/assets/lifecycle.html-CLBCRSkm.js" as="script"><link rel="prefetch" href="/assets/frame-design.html-Anymflre.js" as="script"><link rel="prefetch" href="/assets/index.html-C9OFN5Wg.js" as="script"><link rel="prefetch" href="/assets/reactive.html-C0DqYkTn.js" as="script"><link rel="prefetch" href="/assets/ref.html-BlROqhvn.js" as="script"><link rel="prefetch" href="/assets/render.html-DQXsMRhT.js" as="script"><link rel="prefetch" href="/assets/responsive-system.html-X-EVgQxp.js" as="script"><link rel="prefetch" href="/assets/index.html-BhKUEhBb.js" as="script"><link rel="prefetch" href="/assets/index.html-RQx-7sok.js" as="script"><link rel="prefetch" href="/assets/1-specification.html-WZopz7M0.js" as="script"><link rel="prefetch" href="/assets/2-basic.html-WoIgTWhs.js" as="script"><link rel="prefetch" href="/assets/index.html-DNSqazvT.js" as="script"><link rel="prefetch" href="/assets/1-memory.html-CKSB10LD.js" as="script"><link rel="prefetch" href="/assets/2-basic.html-BMN_vbqb.js" as="script"><link rel="prefetch" href="/assets/3-quick-start.html-Bv1rk-cX.js" as="script"><link rel="prefetch" href="/assets/index.html-Ba7eMiDA.js" as="script"><link rel="prefetch" href="/assets/Chapter2.html-DOsw3dpc.js" as="script"><link rel="prefetch" href="/assets/Chapter3.html-B302q7tl.js" as="script"><link rel="prefetch" href="/assets/Chapter4.html-AKBklpfv.js" as="script"><link rel="prefetch" href="/assets/Chapter5.html-LDtMqwVI.js" as="script"><link rel="prefetch" href="/assets/Chapter6.html-Ctc_NS5M.js" as="script"><link rel="prefetch" href="/assets/Chapter1.html-BXDbtbVe.js" as="script"><link rel="prefetch" href="/assets/ArrayBuffer.html-r5dI3kkY.js" as="script"><link rel="prefetch" href="/assets/Blob.html-DiLBaCd5.js" as="script"><link rel="prefetch" href="/assets/Object.html-D6z3FCzx.js" as="script"><link rel="prefetch" href="/assets/Promise.html-C0HKfCHH.js" as="script"><link rel="prefetch" href="/assets/Symbol.html-5Wp6ttYW.js" as="script"><link rel="prefetch" href="/assets/bigint.html-DddZZSS-.js" as="script"><link rel="prefetch" href="/assets/generator.html-C9sB8PnF.js" as="script"><link rel="prefetch" href="/assets/iterables.html-xdgXETve.js" as="script"><link rel="prefetch" href="/assets/js-array.html-COykDHzA.js" as="script"><link rel="prefetch" href="/assets/modules.html-Dv4RaxPB.js" as="script"><link rel="prefetch" href="/assets/event-loop.html-XYv0_Juv.js" as="script"><link rel="prefetch" href="/assets/index.html-SKaszz5y.js" as="script"><link rel="prefetch" href="/assets/js-engine.html-B4DzGCpx.js" as="script"><link rel="prefetch" href="/assets/web-api.html-xKsReHGV.js" as="script"><link rel="prefetch" href="/assets/404.html-CLoq8jae.js" as="script"><link rel="prefetch" href="/assets/index.html-Bxt3V8zX.js" as="script"><link rel="prefetch" href="/assets/index.html-CL-f6XN4.js" as="script"><link rel="prefetch" href="/assets/index.html-BrANkhPp.js" as="script"><link rel="prefetch" href="/assets/index.html-BtKgzctD.js" as="script"><link rel="prefetch" href="/assets/index.html-bpcy0RaU.js" as="script"><link rel="prefetch" href="/assets/index.html-CoUhRa-l.js" as="script"><link rel="prefetch" href="/assets/index.html-CHXPxnkB.js" as="script"><link rel="prefetch" href="/assets/index.html-CGch6-qx.js" as="script"><link rel="prefetch" href="/assets/index.html-CPbG0zzI.js" as="script"><link rel="prefetch" href="/assets/index.html-CxiJPFRs.js" as="script"><link rel="prefetch" href="/assets/index.html-5Vzk0mYU.js" as="script"><link rel="prefetch" href="/assets/index.html-DEUeTtPj.js" as="script"><link rel="prefetch" href="/assets/index.html-DwwdJhbO.js" as="script"><link rel="prefetch" href="/assets/index.html-CVAmxNC1.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-Bp9IAFhl.js" as="script"><link rel="prefetch" href="/assets/giscus-C1S_t8z-.js" as="script"><link rel="prefetch" href="/assets/SearchResult-2FrQxiWg.js" as="script"><link rel="prefetch" href="/assets/Card-CPkZ_z6g.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-DTD3w-DM.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><!----><!----><span class="vp-site-name">Hertz</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><span class="font-icon icon fas fa-home" style=""></span><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="前端"><!--[--><span class="font-icon icon fas fa-laptop-code" style=""></span>前端<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/js/variable-type.html" aria-label="JavaScript"><!--[--><span class="font-icon icon iconfont icon-js" style=""></span><!--]-->JavaScript<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/browser/DOM.html" aria-label="浏览器"><!--[--><span class="font-icon icon iconfont icon-browser" style=""></span><!--]-->浏览器<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">框架</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/front-end/vue/frame-design.html" aria-label="Vue"><!--[--><span class="font-icon icon iconfont icon-vuejs" style=""></span><!--]-->Vue<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/front-end/react/intro.html" aria-label="React"><!--[--><span class="font-icon icon iconfont icon-react" style=""></span><!--]-->React<!----></a></li></ul></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/front-end/configuration//1-module.html" aria-label="工程化"><!--[--><span class="font-icon icon iconfont icon-project" style=""></span><!--]-->工程化<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/dev/" aria-label="开发相关"><!--[--><span class="font-icon icon fas fa-code" style=""></span><!--]-->开发相关<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="coding"><!--[--><span class="font-icon icon fas fa-keyboard" style=""></span>coding<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/data-structure/1-intro.html" aria-label="数据结构"><!--[--><span class="font-icon icon iconfont icon-ds" style=""></span><!--]-->数据结构<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/design-pattern/" aria-label="设计模式"><!--[--><span class="font-icon icon iconfont icon-dp" style=""></span><!--]-->设计模式<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/coding/re/" aria-label="正则表达式"><!--[--><span class="font-icon icon iconfont icon-re" style=""></span><!--]-->正则表达式<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="其他"><!--[--><span class="font-icon icon fas fa-lemon" style=""></span>其他<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/ai/huggingface-nlp/" aria-label="huggingface"><!--[--><span class="font-icon icon iconfont icon-huggingface" style=""></span><!--]-->huggingface<!----></a></li></ul></button></div></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/hanzhuo-github/hanzhuo-github.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable active"><span class="font-icon icon iconfont icon-huggingface" style=""></span><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/ai/huggingface-nlp/" aria-label="Hugging Face NLP"><!---->Hugging Face NLP<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">👋	Hugging Face 初步</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/ai/huggingface-nlp/section1/Chapter1.html" aria-label="1. Transformer Models"><!---->1. Transformer Models<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter2.html" aria-label="2. 使用 🤗 Transformers"><!---->2. 使用 🤗 Transformers<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter3.html" aria-label="3. 微调预训练模型"><!---->3. 微调预训练模型<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/huggingface-nlp/section1/Chapter4.html" aria-label="4. 共享 Models 和 Tokenizers"><!---->4. 共享 Models 和 Tokenizers<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">👌 Hugging Face 深入</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">🤟 Hugging Face 高级</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon iconfont icon-rl" style=""></span><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/ai/deep-rl/" aria-label="Deep RL"><!---->Deep RL<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/" aria-label="Introduction"><!---->Introduction<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/q-learning.html" aria-label="Q-learning"><!---->Q-learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/deep-q-learning.html" aria-label="Deep Q-learning"><!---->Deep Q-learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/deep-rl/policy-gradient.html" aria-label="Policy Gradient with PyTorch"><!---->Policy Gradient with PyTorch<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><span class="font-icon icon iconfont icon-theory" style=""></span><span class="vp-sidebar-title">理论</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/theory/metrics.html" aria-label="机器学习的评价指标"><!---->机器学习的评价指标<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header clickable"><span class="font-icon icon iconfont icon-book" style=""></span><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/ai/statisticalLearning/" aria-label="ISL"><!---->ISL<!----></a><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/ai/statisticalLearning/" aria-label="链接"><!---->链接<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/ai/statisticalLearning/introduction.html" aria-label="简介"><!---->简介<!----></a></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->1. Transformer Models</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Hertz</span></span><span property="author" content="Hertz"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2024年12月24日</span><meta property="datePublished" content="2024-12-24T06:48:31.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 7 分钟</span><meta property="timeRequired" content="PT7M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><div class="vp-toc-header">此页内容<!----><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-nlp-介绍">1. NLP 介绍</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-术语-architectures-vs-checkpoints">1.1 术语：Architectures vs. checkpoints</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-transformers-能做什么">2. Transformers 能做什么</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-快速体验-🤗-transformers-库">2.1 快速体验 🤗 Transformers 库</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-局限性-偏见">2.2 局限性 &amp; 偏见</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-transformer-背景知识">3. Transformer 背景知识</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-transformer-是语言模型-language-model">3.1 Transformer 是语言模型（language model）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-transformer-是大模型">3.2 Transformer 是大模型</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-3-迁移学习-transfer-learning">3.3 迁移学习（Transfer Learning）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-transformer-结构">4. Transformer 结构</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-1-注意力层-attention-layers">4.1 注意力层（Attention Layers）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-2-原始模型">4.2 原始模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_5-小结">5. 小结</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h2 id="_1-nlp-介绍" tabindex="-1"><a class="header-anchor" href="#_1-nlp-介绍"><span>1. NLP 介绍</span></a></h2><p>NLP 的任务不仅仅是理解单个字词的含义，而是要理解上下文的含义。</p><p>NLP 任务有很多，比如：</p><ul><li><strong>对整个句子进行分类</strong>：获取评论的情绪，检测电子邮件是否为垃圾邮件，确定句子在语法上是否正确或两个句子在逻辑上是否相关</li><li><strong>对句子中的每个词语进行分类</strong>：识别句子的语法成分（名词、动词、形容词）或命名实体（人、地点、组织）</li><li><strong>生成上下文</strong>：用自动生成的文本完成提示，用屏蔽词填充文本中的空白</li><li><strong>从文本中提取答案</strong>：给定问题和上下文，根据上下文中提供的信息提取问题的答案</li><li><strong>根据输入文本生成新的句子</strong>：将文本翻译成另一种语言，总结文本</li></ul><h3 id="_1-1-术语-architectures-vs-checkpoints" tabindex="-1"><a class="header-anchor" href="#_1-1-术语-architectures-vs-checkpoints"><span>1.1 术语：Architectures vs. checkpoints</span></a></h3><p>在接下来的学习中，你将会看到 architectures、checkpoints，还有 models 这些术语。</p><ul><li>Architecture: 模型框架。每一层的定义、模型中发生的每个操作的定义。</li><li>Checkpoints: 对于一个给定 architecture 的权重。</li><li>Model: 范语，可能是指 architecture，也可能是指 checkpoints。</li></ul><p>如：BERT 是一个 architecture。bert-base-cased 是由 Google 团队为 BERT 训练的初始权重，它是 checkpoints。我们可以说 BERT model，也可以说 bert-base-cased model.</p><h2 id="_2-transformers-能做什么" tabindex="-1"><a class="header-anchor" href="#_2-transformers-能做什么"><span>2. Transformers 能做什么</span></a></h2><p>你可以使用<a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">🤗 Transformers 库</a>来创建并使用公开的模型。你可以在<a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">模型中心</a>中查找预训练模型。你也可以在 Hub 中上传你自己的模型。</p><h3 id="_2-1-快速体验-🤗-transformers-库" tabindex="-1"><a class="header-anchor" href="#_2-1-快速体验-🤗-transformers-库"><span>2.1 快速体验 🤗 Transformers 库</span></a></h3><p>🤗 Transformers 库提供了 <code>pipeline()</code> 函数，它聚合了预训练模型和对应的文本预处理。使用该函数可以直接根据输入返回目标输出。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 选择任务 sentiment-analysis，创建分类器对象</span></span>
<span class="line"><span class="token comment"># 没有指定 model，则会使用默认 model</span></span>
<span class="line">classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;sentiment-analysis&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 1 传入一个句子</span></span>
<span class="line">classifier<span class="token punctuation">(</span><span class="token string">&quot;I&#39;ve been waiting for a HuggingFace course my whole life.&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 结果：[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9598048329353333}]</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 2 传入多个句子</span></span>
<span class="line">classifier<span class="token punctuation">(</span></span>
<span class="line">    <span class="token punctuation">[</span><span class="token string">&quot;I&#39;ve been waiting for a HuggingFace course my whole life.&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;I hate this so much!&quot;</span><span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 结果</span></span>
<span class="line"><span class="token comment"># [{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9598048329353333},</span></span>
<span class="line"><span class="token comment">#  {&#39;label&#39;: &#39;NEGATIVE&#39;, &#39;score&#39;: 0.9994558691978455}]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>目前支持的 pipeline 见 <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Model 中心</a>。 如果不想使用默认模型，可通过 <code>model</code> 参数传递对应的模型名称。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline</span>
<span class="line"></span>
<span class="line">generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;text-generation&quot;</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;distilgpt2&quot;</span><span class="token punctuation">)</span></span>
<span class="line">generator<span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&quot;In this course, we will teach you how to&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    max_length<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span></span>
<span class="line">    num_return_sequences<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-局限性-偏见" tabindex="-1"><a class="header-anchor" href="#_2-2-局限性-偏见"><span>2.2 局限性 &amp; 偏见</span></a></h3><p>为了在大规模数据上进行预训练，研究员们会收集尽可能多的数据，这其中可能会夹杂一些意识形态或者价值观的刻板印象。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline</span>
<span class="line"></span>
<span class="line">unmasker <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;fill-mask&quot;</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;bert-base-uncased&quot;</span><span class="token punctuation">)</span></span>
<span class="line">result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">&quot;This man works as a [MASK].&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">&quot;token_str&quot;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">&quot;This woman works as a [MASK].&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">&quot;token_str&quot;</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">[&#39;lawyer&#39;, &#39;carpenter&#39;, &#39;doctor&#39;, &#39;waiter&#39;, &#39;mechanic&#39;]</span>
<span class="line">[&#39;nurse&#39;, &#39;waitress&#39;, &#39;teacher&#39;, &#39;maid&#39;, &#39;prostitute&#39;]</span>
<span class="line"></span></code></pre></div><p>观察结果，有明显的性别相关性，妓女成为了“女性工作”相关的前五名答案之一。</p><div class="hint-container warning"><p class="hint-container-title">注意</p><p>原始模型中很容易掺杂性别歧视、种族歧视等问题，在模型上进一步微调并不会消除这种偏差。</p></div><h2 id="_3-transformer-背景知识" tabindex="-1"><a class="header-anchor" href="#_3-transformer-背景知识"><span>3. Transformer 背景知识</span></a></h2><p>Transformer 架构于 2017 年 6 月推出。大体上可以将 Transformer 模型分为三类：</p><ul><li>GPT-like (自回归（auto-regressive）Transformer 模型)</li><li>BERT-like (自编码（auto-encoding）Transformer 模型)</li><li>BART/T5-like (序列到序列（sequence-to-sequence）Transformer 模型)</li></ul><h3 id="_3-1-transformer-是语言模型-language-model" tabindex="-1"><a class="header-anchor" href="#_3-1-transformer-是语言模型-language-model"><span>3.1 Transformer 是语言模型（language model）</span></a></h3><p>包括 GPT、BERT、BART、T5 等 Transformer 模型都是语言模型，即他们已经以自监督学习（self-supervised）的方式在大量文本上进行了训练。</p><p>这类模型在其进行训练的语料上进行了理解，但是对于具体问题，它就没那么有针对性了，于是我们需要进行迁移学习（transfer learning）。在迁移学习时，对于具体问题，我们使用人工标注的数据以有监督的方式进行精调（fine-tune）。</p><h3 id="_3-2-transformer-是大模型" tabindex="-1"><a class="header-anchor" href="#_3-2-transformer-是大模型"><span>3.2 Transformer 是大模型</span></a></h3><p>实现更好性能的一般策略是增加模型的大小以及预训练的数据量。</p><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/model_parameters.png" width="60%"><h3 id="_3-3-迁移学习-transfer-learning" tabindex="-1"><a class="header-anchor" href="#_3-3-迁移学习-transfer-learning"><span>3.3 迁移学习（Transfer Learning）</span></a></h3><p>预训练（Pretraining）指从头开始训练模型。这往往需要使用大规模语料，花费长达数周的时间。</p><p>微调（Fine-tuning）是在预训练好的模型上进行进一步的训练。要进行微调，你需要使用预训练模型以及针对特定任务的数据集再次进行训练。进行微调可以有效降低时间、设备成本，使用更小的数据集完成。</p><h2 id="_4-transformer-结构" tabindex="-1"><a class="header-anchor" href="#_4-transformer-结构"><span>4. Transformer 结构</span></a></h2><div class="hint-container info"><p class="hint-container-title">扩展阅读</p><p>推荐 <a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">The Illustrated Transformer</a> 这篇文章。在该文章中，作者使用动图清晰地描述了 Transformer 的结构和原理。</p></div><p>Transformer 主要由两部分组成：</p><ul><li>Encoders (编码器): 编码器接收输入并构建其表示（即特征）。这意味着对模型进行了优化，以从输入中获得理解。</li><li>Decoders (解码器): 解码器使用编码器的表示（特征）以及其他输入来生成目标序列。这意味着该模型已针对生成输出进行了优化。</li></ul><p>这两部分可以单独使用，这取决于你要做什么任务：</p><ul><li><p><strong>Encoder-only 模型（auto-encoding models）</strong>：适用于需要理解输入的任务，如句子分类和命名实体识别。</p><p>这类模型有 <a href="https://huggingface.co/docs/transformers/model_doc/albert" target="_blank" rel="noopener noreferrer">ALBERT</a>, <a href="https://huggingface.co/docs/transformers/model_doc/bert" target="_blank" rel="noopener noreferrer">BERT</a>, <a href="https://huggingface.co/docs/transformers/model_doc/distilbert" target="_blank" rel="noopener noreferrer">DistillBERT</a>, <a href="https://huggingface.co/docs/transformers/model_doc/electra" target="_blank" rel="noopener noreferrer">ELECTRA</a>, <a href="https://huggingface.co/docs/transformers/model_doc/roberta" target="_blank" rel="noopener noreferrer">RoBERTa</a></p></li><li><p><strong>Decoder-only 模型（auto-regressive models）</strong>：适用于生成任务，如文本生成。</p><p>这类模型有 <a href="https://huggingface.co/docs/transformers/model_doc/ctrl" target="_blank" rel="noopener noreferrer">CTRL</a>, <a href="https://huggingface.co/docs/transformers/model_doc/openai-gpt" target="_blank" rel="noopener noreferrer">GPT</a>, <a href="https://huggingface.co/docs/transformers/model_doc/gpt2" target="_blank" rel="noopener noreferrer">GPT-2</a>, <a href="https://huggingface.co/docs/transformers/model_doc/transfo-xl" target="_blank" rel="noopener noreferrer">Transformer XL</a></p></li><li><p><strong>Encoder-decoder 模型（sequence-to-sequence models）</strong>：适用于需要根据输入进行生成的任务，如翻译或摘要。预训练这类模型可以使用 encode 或 decoder 的目标。</p><p>这类模型有 <a href="https://huggingface.co/docs/transformers/model_doc/bart" target="_blank" rel="noopener noreferrer">BART</a>, <a href="https://huggingface.co/docs/transformers/model_doc/mbart" target="_blank" rel="noopener noreferrer">mBART</a>, <a href="https://huggingface.co/docs/transformers/model_doc/marian" target="_blank" rel="noopener noreferrer">Marian</a>, <a href="https://huggingface.co/docs/transformers/model_doc/t5" target="_blank" rel="noopener noreferrer">T5</a></p></li></ul><h3 id="_4-1-注意力层-attention-layers" tabindex="-1"><a class="header-anchor" href="#_4-1-注意力层-attention-layers"><span>4.1 注意力层（Attention Layers）</span></a></h3><p>注意力层使得模型对不同位置的字词有着不同的关注程度。</p><p>比如，在做文本翻译任务时，将 &quot;I like eating apples&quot; 翻译成中文，在翻译 like 时，模型需要关注 I 和 eating 来获得正确的翻译，而对 apples 的关注度可能小一些；翻译 &quot;It feels like a soft blanket&quot; 时，关注 feels 会帮助模型获得正确的翻译。</p><h3 id="_4-2-原始模型" tabindex="-1"><a class="header-anchor" href="#_4-2-原始模型"><span>4.2 原始模型</span></a></h3><p>Transformer 最开始是为了翻译任务而设计的。</p><p>在训练过程中，encoder 和 decoder 分别接收两种语言的同一个句子。encoder 使用注意力层，可以“看到”该句子中的全部字词。而 decoder 只能看到已经翻译好的字词（即在正在被翻译的字词之前已经生成的部分）。 比如 decoder 已经生成了3个单词，在生成第4个单词时，我们会把前三个单词也作为输入，连同 encoder 输出的部分一起作为 decoder 的输入来生成第4个单词。</p><p>为了加快训练，我们会喂给 decoder 完整的目标，但是不允许它使用没有预测的词汇。例如，我们正在预测第4个单词，但是模型看到了目标中的第4个单词，显然这样的模型在实际中不会获得好的效果。</p><p>最初的 Transformer 结构如下：</p><figure><img src="/images/huggingface/section1/transformers.svg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>注意，在 decoder 中，第一个注意力层关注所有 decoder 的过去的输入，第二个注意力层，使用了来自 encoder 的输出。因此它能够获得完整的输入句子来对当前词语进行最佳预测。</p><p>我们还可以使用注意力遮罩层（attention mask）以使得模型关注某些表示。比如，在批处理句子时，会使用填充的方式使句子长度保持一致，填充的内容无意义，我们不希望模型关注它。</p><h2 id="_5-小结" tabindex="-1"><a class="header-anchor" href="#_5-小结"><span>5. 小结</span></a></h2><p>本节内容介绍了 NLP 任务以及如何使用 🤗 Transformers 中的 <code>pipeline()</code> 函数来执行不同的 NLP 任务。你可以在<a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">模型中心</a>中查找模型，按照 Model Card 中的说明或者使用页面上的 inference API 进行使用。</p><p>我们简单介绍了 Transformer 的结构，如果你想做进一步了解，推荐阅读 <a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">The Illustrated Transformer</a>。</p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/hanzhuo-github/hanzhuo-github.github.io/edit/main/src/ai/huggingface-nlp/section1/Chapter1.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><span class="vp-meta-info" data-allow-mismatch="text">2024/12/24 06:48:31</span></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: hanzhuosoul@gmail.com">Hertz</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><!----><a class="route-link auto-link next" href="/ai/huggingface-nlp/section1/Chapter2.html" aria-label="2. 使用 🤗 Transformers"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">2. 使用 🤗 Transformers<!----></div></a></nav><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div class="loading-icon-wrapper" style="display:flex;align-items:center;justify-content:center;height:96px"><svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" preserveAspectRatio="xMidYMid" viewBox="25 25 50 50"><animateTransform attributeName="transform" type="rotate" dur="2s" keyTimes="0;1" repeatCount="indefinite" values="0;360"></animateTransform><circle cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round"><animate attributeName="stroke-dasharray" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="1,200;90,200;1,200"></animate><animate attributeName="stroke-dashoffset" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="0;-35px;-125px"></animate></circle></svg></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2024 Hertz </div></footer></div><!--]--><!--]--><!--[--><!----><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-BhCVjEdW.js" defer></script>
  </body>
</html>
